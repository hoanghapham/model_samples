{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "09d9de97",
      "metadata": {
        "id": "09d9de97"
      },
      "source": [
        "# Power Identification with NN and RNN\n",
        "\n",
        "This is a binary classification task, based on a speech of a speaker, to determine their belonging to coalition or opposition in the government.\n",
        "\n",
        "- [Link to the task](https://touche.webis.de/clef24/touche24-web/ideology-and-power-identification-in-parliamentary-debates.html)\n",
        "- [Full project](https://github.com/daschablume/power-identification?tab=readme-ov-file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e06e26ce",
      "metadata": {
        "id": "e06e26ce"
      },
      "outputs": [],
      "source": [
        "#%%\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from typing import Self\n",
        "import csv\n",
        "import numpy as np\n",
        "import datetime\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import KFold\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from scipy.sparse import csr_matrix\n",
        "from tqdm import tqdm\n",
        "\n",
        "from model_samples.torch.nn import NNClassifier\n",
        "from model_samples.torch.rnn import PositionalEncoder, RNNClassifier\n",
        "from model_samples.utils import TrainConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c15d8a0",
      "metadata": {
        "id": "5c15d8a0"
      },
      "outputs": [],
      "source": [
        "class RawDataset():\n",
        "    \"\"\"Class to hold raw data load directly from the tsv files.\n",
        "    \"\"\"\n",
        "    def __init__(self, ids: list[str], speakers: list[str], texts: list[str], labels: list[int]) -> None:\n",
        "        assert len(ids) == len(speakers) == len(texts) == len(labels), \"All arrays must have the same length\"\n",
        "        self.ids = ids\n",
        "        self.speakers = speakers\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "\n",
        "    def subset(self, index_list: list[int]):\n",
        "\n",
        "        data = RawDataset(\n",
        "            [self.ids[idx] for idx in index_list],\n",
        "            [self.speakers[idx] for idx in index_list],\n",
        "            [self.texts[idx] for idx in index_list],\n",
        "            [self.labels[idx] for idx in index_list],\n",
        "        )\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        return (self.ids[index], self.speakers[index], self.texts[index], self.labels[index])\n",
        "\n",
        "    def __add__(self, other: Self):\n",
        "        return RawDataset(\n",
        "            self.ids + other.ids,\n",
        "            self.speakers + other.speakers,\n",
        "            self.texts + other.texts,\n",
        "            self.labels + other.labels\n",
        "        )\n",
        "\n",
        "    def __iter__(self):\n",
        "        for data in zip(self.ids, self.speakers, self.texts, self.labels):\n",
        "            yield data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "def load_data(file_path) -> RawDataset:\n",
        "    \"\"\"Load one file and return \"\"\"\n",
        "\n",
        "    data = pd.read_csv(file_path, sep=\"\\t\")\n",
        "    return RawDataset(data[\"id\"], data[\"speaker\"], data[\"text\"], data[\"label\"])\n",
        "\n",
        "\n",
        "class EncodedDataset(Dataset):\n",
        "    \"\"\"Custom Dataset object to hold parliament debate data. Each item in the dataset\n",
        "    is a tuple of (input tensor, label)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            inputs: torch.Tensor,\n",
        "            labels: torch.Tensor,\n",
        "        ) -> None:\n",
        "        super().__init__()\n",
        "        assert len(inputs) == len(labels), \"Inputs and labels have different length\"\n",
        "        self.data_ = list(zip(inputs, labels))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.data_[index]\n",
        "\n",
        "    def __iter__(self):\n",
        "        for data in self.data_:\n",
        "            yield data\n",
        "\n",
        "def encode_torch_data(data: RawDataset, encoder: PositionalEncoder | TfidfVectorizer):\n",
        "    \"\"\"Convenience function to create the encoded dataset compatible with torch models\"\"\"\n",
        "    # Encode text\n",
        "    enc_texts_csr = encoder.transform(data.texts)\n",
        "\n",
        "    if isinstance(enc_texts_csr, csr_matrix):\n",
        "        inputs = torch.from_numpy(enc_texts_csr.todense()).float()\n",
        "    else:\n",
        "        inputs = enc_texts_csr.to_dense()\n",
        "\n",
        "    # Convert labels to tensor\n",
        "    labels = torch.tensor(data.labels)\n",
        "\n",
        "    return EncodedDataset(inputs, labels)\n",
        "\n",
        "# Helper functions\n",
        "def get_average_metrics(result_list: list[dict]) -> dict:\n",
        "    accuracy = np.mean([[result['accuracy'] for result in result_list]])\n",
        "    precision = np.mean([[result['precision'] for result in result_list]])\n",
        "    recall = np.mean([[result['recall'] for result in result_list]])\n",
        "    f1 = np.mean([[result['f1'] for result in result_list]])\n",
        "    auc = np.mean([[result['auc'] for result in result_list]])\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc\": auc}\n",
        "\n",
        "\n",
        "def evaluate(y_test: np.ndarray, y_pred: np.ndarray, y_prob: np.ndarray) -> dict:\n",
        "    \"\"\"Conveninece function to evaluate predction of models.\n",
        "\n",
        "    The function returns a dictionary of metrics:\n",
        "    - Accuracy\n",
        "    - Precision\n",
        "    - Recall\n",
        "    - F1\n",
        "    - AUC\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_test : np.ndarray\n",
        "        Labels of the test set\n",
        "    y_pred : np.ndarray\n",
        "        Prediction produced by the model\n",
        "    y_prob : np.ndarray\n",
        "        Probability array produced by the model\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "    \"\"\"\n",
        "\n",
        "    true_pos = sum([pred == y == 1 for pred, y in zip(y_pred, y_test)])\n",
        "    true_neg = sum([pred == y == 0 for pred, y in zip(y_pred, y_test)])\n",
        "    false_pos = sum([(pred == 1) * (y == 0) for pred, y in zip(y_pred, y_test)])\n",
        "    false_neg = sum([(pred == 0) * (y == 1) for pred, y in zip(y_pred, y_test)])\n",
        "    total = len(y_test)\n",
        "\n",
        "    accuracy = (true_pos + true_neg) / total\n",
        "    precision = true_pos / (true_pos + false_pos)\n",
        "    recall = true_pos / (true_pos + false_neg)\n",
        "    f1 = 2 * true_pos / (2 * true_pos + false_pos + false_neg)\n",
        "    auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "    result = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"auc\": auc\n",
        "    }\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbdb50f1",
      "metadata": {
        "id": "dbdb50f1"
      },
      "source": [
        "# Classification with Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfd69087",
      "metadata": {
        "id": "bfd69087"
      },
      "outputs": [],
      "source": [
        "data = load_data(\"./data/power-gb-train.tsv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "46fe0d21",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46fe0d21",
        "outputId": "20d67097-0f0d-46e1-88ea-9dd71e2c8a63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV fold 1\n",
            "Train TfidfVectorizer\n",
            "Run model on GPU\n",
            "\n",
            "Fold 1 train time: 0.2388 minutes\n",
            "CV fold 2\n",
            "Train TfidfVectorizer\n",
            "Run model on GPU\n",
            "\n",
            "Fold 2 train time: 0.1972 minutes\n",
            "CV fold 3\n",
            "Train TfidfVectorizer\n",
            "Run model on GPU\n",
            "\n",
            "Fold 3 train time: 0.1944 minutes\n",
            "CV fold 4\n",
            "Train TfidfVectorizer\n",
            "Run model on GPU\n",
            "\n",
            "Fold 4 train time: 0.1951 minutes\n",
            "CV fold 5\n",
            "Train TfidfVectorizer\n",
            "Run model on GPU\n",
            "\n",
            "Fold 5 train time: 0.1914 minutes\n",
            "['accuracy: 0.757', 'precision: 0.785', 'recall: 0.785', 'f1: 0.785', 'auc: 0.834']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "NFOLDS = 5\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "result_list = []\n",
        "kfold = KFold(n_splits=NFOLDS, shuffle=False, random_state=None)\n",
        "\n",
        "for fold_idx, (train_idx, test_idx) in enumerate(kfold.split(data), start=1):\n",
        "    print(f\"CV fold {fold_idx}\")\n",
        "\n",
        "    print(\"Train TfidfVectorizer\")\n",
        "    encoder = TfidfVectorizer(max_features=10000, analyzer=\"char\", ngram_range=(3,5), use_idf=True, sublinear_tf=True)\n",
        "    encoder.fit(data.subset(train_idx).texts)\n",
        "\n",
        "    # Encode data\n",
        "    train_data = encode_torch_data(data.subset(train_idx), encoder)\n",
        "    test_data = encode_torch_data(data.subset(test_idx), encoder)\n",
        "\n",
        "    # Init model\n",
        "    train_config = TrainConfig(\n",
        "        num_epochs      = 10,\n",
        "        early_stop      = False,\n",
        "        violation_limit = 5\n",
        "    )\n",
        "\n",
        "    dataloader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "\n",
        "    model = NNClassifier(\n",
        "        input_size=len(encoder.vocabulary_),\n",
        "        hidden_size=128,\n",
        "        n_linear_layers=3,\n",
        "        device=DEVICE\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    t0 = datetime.datetime.now()\n",
        "    model.fit(dataloader, train_config, disable_progress_bar=True)\n",
        "    time_elapsed = (datetime.datetime.now() - t0).total_seconds()\n",
        "\n",
        "    print(f\"Fold {fold_idx} train time: {time_elapsed / 60:.4} minutes\")\n",
        "\n",
        "\n",
        "    # Evaluate\n",
        "    with torch.no_grad():\n",
        "        X_test_nn = torch.stack([test[0] for test in test_data]).cpu()\n",
        "        y_test_nn = torch.stack([test[1] for test in test_data]).cpu()\n",
        "        y_pred_nn = model.predict(X_test_nn)\n",
        "        logits_nn = model.forward(X_test_nn)\n",
        "\n",
        "    result = evaluate(y_test_nn.cpu(), y_pred_nn.cpu(), logits_nn.cpu())\n",
        "    result_list.append({\"fold\": str(fold_idx), **result})\n",
        "\n",
        "\n",
        "avg_nn_results = get_average_metrics(result_list)\n",
        "print([f\"{key}: {value:.3f}\" for key, value in avg_nn_results.items()])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96d6069a",
      "metadata": {
        "id": "96d6069a"
      },
      "source": [
        "# Classification with RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e565c0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e565c0e",
        "outputId": "451aecf7-8a41-4782-c57b-da0fdbd15ddf"
      },
      "outputs": [],
      "source": [
        "\n",
        "NFOLDS = 5\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "result_list = []\n",
        "kfold = KFold(n_splits=NFOLDS, shuffle=False)\n",
        "\n",
        "for fold_idx, (train_idx, test_idx) in enumerate(kfold.split(data), start=1):\n",
        "    print(f\"CV fold {fold_idx}\")\n",
        "\n",
        "    chars_encoder = TfidfVectorizer(max_features=50000, analyzer=\"char\", ngram_range=(3,5), use_idf=True, sublinear_tf=True)\n",
        "    encoder = PositionalEncoder(tokenizer=chars_encoder.build_tokenizer())\n",
        "    encoder.fit(data.subset(train_idx).texts)\n",
        "\n",
        "    train_dataloader = DataLoader(data.subset(train_idx), batch_size=128, shuffle=True)\n",
        "    test_dataloader = DataLoader(data.subset(test_idx), batch_size=128, shuffle=False)\n",
        "\n",
        "    # Prepare baseline config\n",
        "    train_config = TrainConfig(\n",
        "        optimizer_params = {'lr': 0.01},\n",
        "        num_epochs       = 10,\n",
        "        early_stop       = False,\n",
        "        violation_limit  = 5\n",
        "    )\n",
        "\n",
        "    # Train baseline model\n",
        "    model = RNNClassifier(\n",
        "        rnn_network         = nn.LSTM,\n",
        "        word_embedding_dim  = 32,\n",
        "        hidden_dim          = 64,\n",
        "        bidirectional       = False,\n",
        "        dropout             = 0,\n",
        "        encoder             = encoder,\n",
        "        device              = DEVICE\n",
        "    )\n",
        "\n",
        "    t0 = datetime.datetime.now()\n",
        "    model.fit(train_dataloader, train_config, disable_progress_bar=True)\n",
        "\n",
        "    time_elapsed = (datetime.datetime.now() - t0).total_seconds()\n",
        "    print(f\"Fold {fold_idx} train time: {time_elapsed / 60:.4} minutes\")\n",
        "\n",
        "\n",
        "    # Evaluate\n",
        "    with torch.no_grad():\n",
        "        model.device = \"cpu\"\n",
        "        model.cpu()\n",
        "\n",
        "        pred_lst = []\n",
        "        probs_lst = []\n",
        "\n",
        "        for _, _, raw_inputs, raw_targets in test_dataloader:\n",
        "            batch_encoder = PositionalEncoder(vocabulary=encoder.vocabulary)\n",
        "            test_inputs = batch_encoder.fit_transform(raw_inputs).cpu()\n",
        "            # test_targets = torch.as_tensor(raw_targets, dtype=torch.float).cpu()\n",
        "\n",
        "            pred_lst.append(model.predict(test_inputs))\n",
        "            probs_lst.append(model._sigmoid(model.forward(test_inputs)).squeeze())\n",
        "\n",
        "    pred = torch.cat(pred_lst).long().numpy()\n",
        "    probs = torch.concat(probs_lst).numpy()\n",
        "\n",
        "    result = evaluate(data.subset(test_idx).labels, pred, probs)\n",
        "    result_list.append({\"fold\": str(fold_idx), **result})\n",
        "\n",
        "\n",
        "avg_rnn_results = get_average_metrics(result_list)\n",
        "print([f\"{key}: {value:.3f}\" for key, value in avg_rnn_results.items()])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
